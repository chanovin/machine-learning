str(corrcars)
ggplot(mtcars, aes(x=am, y=mpg)) + geom_boxplot()
ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot()
pairs(corrcars)
?mtcars
?lm
transOnlyFit <- lm(mpg~am, data=corrcars)
summary transOnlyFit
summary(transOnlyFit)
plot(transOnlyFit$residuals)
pairs(corrcars)
cor(pairs(corrcars))
cor()
cor(corrcars)
?cor
cor(corrcars$am, corrcars[,-am])
cor(corrcars$am, corrcars[,.-am])
str(corrcars)
cor(corrcars$am, corrcars[,-9])
plot(transOnlyFit$residuals, color=corrcars$cyl)
?plot
plot(transOnlyFit$residuals, col=corrcars$cyl)
plot(transOnlyFit$residuals, col=corrcars$disp)
plot(transOnlyFit$residuals, col=corrcars$hp)
plot(transOnlyFit$residuals, col=corrcars$drat)
plot(transOnlyFit$residuals, col=corrcars$wt)
plot(transOnlyFit$residuals, col=corrcars$qsec)
plot(transOnlyFit$residuals, col=corrcars$vs)
cor(transOnlyFit$residuals, corrcars$vs)
cor(transOnlyFit$residuals, as.numeric(corrcars$vs))
plot(transOnlyFit$residuals, col=corrcars$gear)
plot(transOnlyFit$residuals, col=corrcars$carb)
plot(transOnlyFit$residuals, col=corrcars$cyl)
plot(transOnlyFit$residuals, col=corrcars$disp)
plot(transOnlyFit$residuals, col=corrcars$hp)
plot(transOnlyFit$residuals, col=corrcars$drat)
plot(transOnlyFit$residuals, col=corrcars$wt)
AmVsCylFit <- lm(mpg~am+vs+cyl)
AmVsCylFit <- lm(mpg~am+vs+cyl, data=corrcars)
summary(AmVsCylFit)
summary(transOnlyFit)
anova(transOnlyFit,AmVsCylFit)
AmVsFit <- lm(mpg~am+vs,data=corrcars)
anova(transOnlyFit,AmVsFit,AmVsCylFit)
cor(as.integer(corrcars$am))
cor(as.integer(corrcars$am),as.integer(corrcars$vs))
cor(as.integer(corrcars$am),as.integer(corrcars$cyl))
cor(as.integer(corrcars$vs),as.integer(corrcars$cyl))
cor(as.integer(corrcars$vs),(corrcars$cyl))
AmCylFit <- lm(mpg~am+cyl,data=corrcars)
summary(c(amCylFit,AmVsFit))
summary(c(AmCylFit,AmVsFit))
summary(AmCylFit)
summary(AmVsFit)
AmDispFit <- lm(mpg~am+disp,data=corrcars)
summary(AmDispFit)
plot(transOnlyFit$residuals, col=corrcars$disp)
plot(transOnlyFit$residuals~corrcars$disp)
plot(transOnlyFit$residuals~corrcars$cyl)
plot(transOnlyFit$residuals~corrcars$disp)
plot(AmDispFit$residuals~corrcars$mpg)
plot(AmDispFit$residuals~corrcars$cyl)
plot(AmDispFit$residuals~corrcars$hp)
plot(AmDispFit$residuals~corrcars$drat)
plot(AmDispFit$residuals~corrcars$wt)
plot(AmDispFit$residuals~corrcars$qsec)
plot(AmDispFit$residuals~corrcars$vs)
plot(AmDispFit$residuals~corrcars$gear)
plot(AmDispFit$residuals~corrcars$carb)
pairs(AmDispFit)
plot(mpg~disp,data=corrcars,col=am)
t.test(mpg~am+disp, data=corrcars)
t.test(mpg~am, data=corrcars)
t.test(mpg~disp, data=corrcars)
summary(aov(mpg~.,data=corrcars))
summary(aov(mpg~cyl+disp+wt,data=corrcars))
bestfit <- lm(mpg~cyl+wt+disp,data=corrcars)
bestfitplus <- lm(mpg~cyl+wt+disp,data=corrcars)
anova(bestfit,bestfitplus)
bestfit <- lm(mpg~cyl+wt+disp,data=corrcars)
bestfitplus <- lm(mpg~cyl+wt+disp+am,data=corrcars)
anova(bestfit,bestfitplus)
plot(bestfit$residuals)
plot(bestfit$residuals~am)
plot(bestfit$residuals~corrcars$am)
plot(bestfit,which=1)
par(mfrow=c(2,3))
plot(bestfit,which=1)
plot(bestfit,which=2)
plot(bestfit,which=3)
plot(bestfit,which=4)
plot(bestfit,which=5)
plot(bestfit,which=6)
?vif
vif(bestfit)
library(car)
vif(bestfit)
cylwtfit <- lm(mpg~cyl+wt,data=corrcars)
vif(cylwtfit)
anova(cylwtfit,bestfit)
cylwtamfit <- lm(mpg~cyl+wt+am,data=corrcars)
anova(cylwtfit,cylwtamfit)
summary(cylwtamfit)
summary(cylwtfit)
## lets do some quick diagnostics
par(mfrow=c(2,3))
plot(cylwtfit,which=1)
plot(cylwtfit,which=2)
plot(cylwtfit,which=3)
plot(cylwtfit,which=4)
plot(cylwtfit,which=5)
plot(cylwtfit,which=6)
## lets do some quick diagnostics
par(mfrow=c(2,3))
plot(cylwtfit,which=1)
plot(cylwtfit,which=2)
plot(cylwtfit,which=3)
plot(cylwtfit,which=4)
plot(cylwtfit,which=5)
plot(cylwtfit,which=6)
plot()
plot(cylwtfit$residuals)
## lets do some quick diagnostics
par(mfrow=c(2,3))
plot(cylwtfit,which=1)
plot(cylwtfit,which=2)
plot(cylwtfit,which=3)
plot(cylwtfit,which=4)
plot(cylwtfit,which=5)
plot(cylwtfit,which=6)
plot(cylwtfit$residuals~corrcars$mpg)
plot(cylwtfit$residuals~corrcars$disp)
plot(cylwtfit$residuals~corrcars$hp)
plot(cylwtfit$residuals~corrcars$drat)
plot(cylwtfit$residuals~corrcars$qsec)
plot(cylwtfit$residuals~corrcars$gears)
plot(cylwtfit$residuals~corrcars$gear)
plot(cylwtfit$residuals~corrcars$carb)
par(mfrow=c(2,4))
plot(cylwtfit$residuals~corrcars$am)
plot(cylwtfit$residuals~corrcars$mpg)
plot(cylwtfit$residuals~corrcars$disp)
plot(cylwtfit$residuals~corrcars$hp)
plot(cylwtfit$residuals~corrcars$drat)
plot(cylwtfit$residuals~corrcars$qsec)
plot(cylwtfit$residuals~corrcars$gears)
plot(cylwtfit$residuals~corrcars$gear)
plot(cylwtfit$residuals~corrcars$carb)
str(corrcars)
ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot()
ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot() + ggtitle("MPG by transmission")
explbox <- ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot() + ggtitle("MPG by transmission")
explpr <- pairs(corrcars)
multiplot(explbox,explpr,cols=2)
library(ggplot2)
explbox <- ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot() + ggtitle("MPG by transmission")
explpr <- pairs(corrcars)
multiplot(explbox,explpr,cols=2)
library(grid)
explbox <- ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot() + ggtitle("MPG by transmission")
explpr <- pairs(corrcars)
multiplot(explbox,explpr,cols=2)
?multiplot
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
# Code from Winston Chang, www.cookbook-r.com
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
explbox <- ggplot(corrcars, aes(x=am, y=mpg)) + geom_boxplot() + ggtitle("MPG by transmission")
explpr <- pairs(corrcars)
multiplot(explbox,explpr,cols=2)
t.test(mpg~am,data=corrcars)
summary(aov(mpg~.,data=corrcars))
bestfit <- lm(mpg~cyl+wt+disp,data=corrcars)
bestfitplus <- lm(mpg~cyl+wt+disp+am,data=corrcars)
anova(bestfit,bestfitplus)
summary(cylwtamfit)
anova(cylwtfit,cylwtamfit)
par(mfrow=c(2,3))
plot(cylwtfit,which=1)
plot(cylwtfit,which=2)
plot(cylwtfit,which=3)
plot(cylwtfit,which=4)
plot(cylwtfit,which=5)
plot(cylwtfit,which=6)
par(mfrow=c(2,4))
plot(cylwtfit$residuals~corrcars$am)
plot(cylwtfit$residuals~corrcars$mpg)
plot(cylwtfit$residuals~corrcars$disp)
plot(cylwtfit$residuals~corrcars$hp)
plot(cylwtfit$residuals~corrcars$drat)
plot(cylwtfit$residuals~corrcars$qsec)
plot(cylwtfit$residuals~corrcars$gear)
plot(cylwtfit$residuals~corrcars$carb)
pairs(corrcars)
cylwtamfit$coefficients
cylwtamfit$fitted.values
cylwtamfit$residuals
cylwtamfit$effects
cylwtamfit$rank
cylwtamfit$assign
cylwtamfit$df.residual
cylwtamfit$terms
?latex_engine
## Project Script File
## Coursera Machine Learning Course
## Author: Vincent Chan
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
str(training)
## there appear to be a lot of NAs for the distribution data. are these data one observation per rep
## or is it one set of observations with temporally adjacent timestamp per rep?
## compare to the test set
str(testing)
## test set gives us 20 obs, so we need to determine the class of exercise based only on
## instantaneous data. we can discard all of the new_window data
## next to new_window (y/n) there is a num_window. probably corresponding to the rep.
## discard this for now.
## identify non-important variables
## user_name: should be independent of who does the exercise bc the movement is either correct or not
## raw_timestamp_part_1: time/date info should not affect quality of exercise
## raw_timestamp_part_2: see above
## cvtd_timestamp: see above
## new_window: indicates that a line is the completed rep summary info (we can recalculate this)
## any summary data for each rep (we can calculate this on our own if we need it)
## possible important variables:
## num_window: could be useful for performing summaries for each rep
## classe: outcome data
## all movement metrics data
## let's clean up the data somewhat
## drop rows that are new_windows
training <- training[which(training$new_window!="yes"),]
## drop IDed cols
training <- subset(training,select=-c(user_name, raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp, new_window))
## drop NA cols
training <- training[,colSums(is.na(training)) != nrow(training)]
## still need to drop kurtosis, skewness, max, min, amplitude
training <- subset(training,select=-c(kurtosis_roll_belt,kurtosis_picth_belt,kurtosis_yaw_belt,
skewness_roll_belt,skewness_roll_belt.1,skewness_yaw_belt,
max_yaw_belt,min_yaw_belt,amplitude_yaw_belt))
training <- subset(training,select=-c(kurtosis_roll_arm,
kurtosis_picth_arm,kurtosis_yaw_arm,skewness_roll_arm,
skewness_pitch_arm,skewness_yaw_arm))
training <- subset(training,select=-c(kurtosis_roll_dumbbell,
kurtosis_picth_dumbbell,kurtosis_yaw_dumbbell,
skewness_roll_dumbbell,skewness_pitch_dumbbell,
skewness_yaw_dumbbell,max_yaw_dumbbell,min_yaw_dumbbell,
amplitude_yaw_dumbbell))
training <-  subset(training,select=-c(kurtosis_roll_forearm,kurtosis_picth_forearm,
kurtosis_yaw_forearm,skewness_roll_forearm,
skewness_pitch_forearm,skewness_yaw_forearm,
max_yaw_forearm,min_yaw_forearm, amplitude_yaw_forearm))
## lastly, X appears to be an index value
training <- subset(training,select=-X)
## now we should be down to the usable variables
## split the data set for cross-validation
## our training set is rather large, so we'll use 1/2 of it for validation and 1/2 for training
set.seed(314159)
indexTrain = createDataPartition(training$classe, p = 1/2)[[1]]
trainset = training[ indexTrain,]
valset = training[-indexTrain,]
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
## create three models
mod1 <- train(classe~.,data=trainset,method="gbm")
mod2 <- train(classe~.,data=trainset,method="rf")
mod3 <- train(classe~.,data=trainset,method="lda")
## check the models vs actual values for reasonable in-sample accuracy
predTr1 <- predict(mod1, trainset)
predTr2 <- predict(mod2, trainset)
predTr3 <- predict(mod3, trainset)
table(predTr1,trainset$classe)
sum(predTr1==trainset$classe)/length(trainset$classe)
table(predTr2,trainset$classe)
sum(predTr2==trainset$classe)/length(trainset1$classe)
table(predTr3,trainset$classe)
sum(predTr3==trainset$classe)/length(trainset$classe)
## 2 is best with 1 close and 3 doing poorly
## check the models for out-of-sample accuracy against our valset
predval1 <- predict(mod1,valset)
predval2 <- predict(mod2, valset)
predval3 <- predict(mod3, valset)
table(predval1, valset$classe)
sum(predval1==valset$classe)/length(valset$classe)
table(predval2, valset$classe)
sum(predval2==valset$classe)/length(valset$classe)
table(predval3, valset$classe)
sum(predval3==valset$classe)/length(valset$classe)
## 2 continues to outperform 1 by just a touch
## we'll apply it to the test set now
predtest2 <- predict(mod2,testing)
## Project Script File
## Coursera Machine Learning Course
## Author: Vincent Chan
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
str(training)
## there appear to be a lot of NAs for the distribution data. are these data one observation per rep
## or is it one set of observations with temporally adjacent timestamp per rep?
## compare to the test set
str(testing)
## test set gives us 20 obs, so we need to determine the class of exercise based only on
## instantaneous data. we can discard all of the new_window data
## next to new_window (y/n) there is a num_window. probably corresponding to the rep.
## discard this for now.
## identify non-important variables
## user_name: should be independent of who does the exercise bc the movement is either correct or not
## raw_timestamp_part_1: time/date info should not affect quality of exercise
## raw_timestamp_part_2: see above
## cvtd_timestamp: see above
## new_window: indicates that a line is the completed rep summary info (we can recalculate this)
## any summary data for each rep (we can calculate this on our own if we need it)
## possible important variables:
## num_window: could be useful for performing summaries for each rep
## classe: outcome data
## all movement metrics data
## let's clean up the data somewhat
## drop rows that are new_windows
training <- training[which(training$new_window!="yes"),]
## drop IDed cols
training <- subset(training,select=-c(user_name, raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp, new_window))
## drop NA cols
training <- training[,colSums(is.na(training)) != nrow(training)]
## still need to drop kurtosis, skewness, max, min, amplitude
training <- subset(training,select=-c(kurtosis_roll_belt,kurtosis_picth_belt,kurtosis_yaw_belt,
skewness_roll_belt,skewness_roll_belt.1,skewness_yaw_belt,
max_yaw_belt,min_yaw_belt,amplitude_yaw_belt))
training <- subset(training,select=-c(kurtosis_roll_arm,
kurtosis_picth_arm,kurtosis_yaw_arm,skewness_roll_arm,
skewness_pitch_arm,skewness_yaw_arm))
training <- subset(training,select=-c(kurtosis_roll_dumbbell,
kurtosis_picth_dumbbell,kurtosis_yaw_dumbbell,
skewness_roll_dumbbell,skewness_pitch_dumbbell,
skewness_yaw_dumbbell,max_yaw_dumbbell,min_yaw_dumbbell,
amplitude_yaw_dumbbell))
training <-  subset(training,select=-c(kurtosis_roll_forearm,kurtosis_picth_forearm,
kurtosis_yaw_forearm,skewness_roll_forearm,
skewness_pitch_forearm,skewness_yaw_forearm,
max_yaw_forearm,min_yaw_forearm, amplitude_yaw_forearm))
## lastly, X appears to be an index value
training <- subset(training,select=-X)
## now we should be down to the usable variables
## split the data set for cross-validation
## our training set is rather large, so we'll use 1/2 of it for validation and 1/2 for training
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(314159)
indexTrain = createDataPartition(training$classe, p = 1/2)[[1]]
trainset = training[ indexTrain,]
valset = training[-indexTrain,]
## create three models
mod1 <- train(classe~.,data=trainset,method="gbm")
mod2 <- train(classe~.,data=trainset,method="rf")
mod3 <- train(classe~.,data=trainset,method="lda")
## check the models vs actual values for reasonable in-sample accuracy
predTr1 <- predict(mod1, trainset)
predTr2 <- predict(mod2, trainset)
predTr3 <- predict(mod3, trainset)
table(predTr1,trainset$classe)
sum(predTr1==trainset$classe)/length(trainset$classe)
table(predTr2,trainset$classe)
sum(predTr2==trainset$classe)/length(trainset1$classe)
table(predTr3,trainset$classe)
sum(predTr3==trainset$classe)/length(trainset$classe)
## 2 is best with 1 close and 3 doing poorly
## check the models for out-of-sample accuracy against our valset
predval1 <- predict(mod1,valset)
predval2 <- predict(mod2, valset)
predval3 <- predict(mod3, valset)
table(predval1, valset$classe)
sum(predval1==valset$classe)/length(valset$classe)
table(predval2, valset$classe)
sum(predval2==valset$classe)/length(valset$classe)
table(predval3, valset$classe)
sum(predval3==valset$classe)/length(valset$classe)
## 2 continues to outperform 1 by just a touch
## we'll apply it to the test set now
predtest2 <- predict(mod2,testing)
predtest2
rawdat <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
summary(mod2)
mod2
confusionMatrix(predtest2,testing$classe)
?confusionMatrix
plot(mod1)
plot(mod2)
plot(mod3)
plot(mod1)
importance(mod2)
mod1
mod2
rsme(predtest2,testing$classe)
rmse(predtest2,testing$classe)
plot(mod2)
plot(mod2) + title("Random Forests, mtry vs accuracy")
plot(mod2, title("Random Forests, mtry vs accuracy")
)
plot(mod1)
plot(mod2, title="Random Forests, mtry vs accuracy")
plot(mod2, main="Random Forests, mtry vs accuracy")
plot(mod1)
plot(mod1, main="Stochastic Gradient Boosting",sub="iterations and tree depth vs accuracy")
mod1
plot(mod1, main="Stochastic Gradient Boosting \n iterations and tree depth vs accuracy")
mod1
pairs(training)
lm(classe~.,data=training)
predval1 <- predict(mod1,valset)
predval2 <- predict(mod2, valset)
predval3 <- predict(mod3, valset)
table(predval1, valset$classe)
sum(predval1==valset$classe)/length(valset$classe)
table(predval2, valset$classe)
sum(predval2==valset$classe)/length(valset$classe)
table(predval3, valset$classe)
sum(predval3==valset$classe)/length(valset$classe)
?cv
library(caret)
?cv
unlink('GitHub/machine-learning/Project/Project_cache', recursive = TRUE)
load("~/GitHub/machine-learning/Project/Project_cache/html/loaddata_676f166b9dd478ff4512b81480ef6ef8.RData")
load("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.RData")
mod1
install.packages("lazyLoad")
library(lazyLoad)
?lazyload
setwd("~/GitHub/machine-learning/Project/Project_cache/html")
lazyLoad("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.RData")
lazyLoad("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.RDrdx")
lazyLoad("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.rdx")
lazyLoad("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.rdb")
lazyLoad("~/GitHub/machine-learning/Project/Project_cache/html/")
?lazyLoad
?load
loadall("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.RData")
load_all("~/GitHub/machine-learning/Project/Project_cache/html/modelcreation_0adbd3e4ae6a499d66a3be0687a13d29.RData")
library(qwraps2)
install.packages("qwraps2")
library(qwraps2)
lazyload_cache_labels("modelcreation", path="")
?lazyload_cache_labels
lazyLoad("modelcreation",path="")
lazyLoad("modelcreation")
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
training <- training[which(training$new_window!="yes"),]
training <- subset(training,select=-c(user_name, raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp, new_window))
training <- training[,colSums(is.na(training)) != nrow(training)]
training <- subset(training,select=-c(kurtosis_roll_belt,kurtosis_picth_belt,kurtosis_yaw_belt,
skewness_roll_belt,skewness_roll_belt.1,skewness_yaw_belt,
max_yaw_belt,min_yaw_belt,amplitude_yaw_belt))
training <- subset(training,select=-c(kurtosis_roll_arm,
kurtosis_picth_arm,kurtosis_yaw_arm,skewness_roll_arm,
skewness_pitch_arm,skewness_yaw_arm))
training <- subset(training,select=-c(kurtosis_roll_dumbbell,
kurtosis_picth_dumbbell,kurtosis_yaw_dumbbell,
skewness_roll_dumbbell,skewness_pitch_dumbbell,
skewness_yaw_dumbbell,max_yaw_dumbbell,min_yaw_dumbbell,
amplitude_yaw_dumbbell))
training <-  subset(training,select=-c(kurtosis_roll_forearm,kurtosis_picth_forearm,
kurtosis_yaw_forearm,skewness_roll_forearm,
skewness_pitch_forearm,skewness_yaw_forearm,
max_yaw_forearm,min_yaw_forearm, amplitude_yaw_forearm))
training <- subset(training,select=-X)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(314159)
indexTrain = createDataPartition(training$classe, p = 1/2)[[1]]
trainset = training[ indexTrain,]
valset = training[-indexTrain,]
mod1 <- train(classe~.,data=trainset,method="gbm")
predTr1 <- predict(mod1,trainset)
